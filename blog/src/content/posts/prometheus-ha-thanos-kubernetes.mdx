---
title: "Prometheus HA 구성: Thanos로 Kubernetes에서 구축하기"
pubDate: 2025-12-07
description: "Thanos를 활용하여 Kubernetes 환경에서 Prometheus 고가용성(HA) 아키텍처를 구성하는 방법을 심층적으로 다룹니다."
tags: ["prometheus", "thanos", "kubernetes", "monitoring", "ha", "devops"]
draft: false
---

import AnimFlowEmbed from '../../components/AnimFlowEmbed.astro';

# Prometheus HA 구성: Thanos로 Kubernetes에서 구축하기

프로덕션 환경에서 모니터링 시스템의 고가용성은 필수입니다. 단일 Prometheus 인스턴스는 SPOF(Single Point of Failure)가 될 수 있으며, 장기 메트릭 보존과 글로벌 뷰 제공에 한계가 있습니다.

이 글에서는 **Thanos**를 활용하여 이러한 한계를 극복하는 방법을 다룹니다.

## Prometheus 단독 구성의 한계

기존 Prometheus 단독 구성의 문제점:

1. **고가용성 부재**: 단일 인스턴스 장애 시 모니터링 중단
2. **수평 확장 불가**: 단일 노드 리소스 제한
3. **장기 보존 어려움**: 로컬 스토리지 의존
4. **글로벌 뷰 부재**: 멀티 클러스터 환경에서 통합 쿼리 불가

## Thanos 아키텍처 개요

Thanos는 Prometheus를 확장하여 위 문제들을 해결합니다.

<AnimFlowEmbed
  id="thanos-architecture"
  title="Thanos Architecture Overview"
  height={500}
  yaml={`version: "1.0"
nodes:
  - id: prom1
    type: box
    label: Prometheus 1
    position: { x: 80, y: 100 }
  - id: prom2
    type: box
    label: Prometheus 2
    position: { x: 80, y: 250 }
  - id: sidecar1
    type: box
    label: Sidecar
    position: { x: 230, y: 100 }
  - id: sidecar2
    type: box
    label: Sidecar
    position: { x: 230, y: 250 }
  - id: store
    type: database
    label: Store Gateway
    position: { x: 380, y: 320 }
  - id: objstore
    type: database
    label: Object Storage (S3)
    position: { x: 530, y: 320 }
  - id: query
    type: box
    label: Thanos Query
    position: { x: 380, y: 175 }
  - id: compact
    type: box
    label: Compactor
    position: { x: 530, y: 100 }
  - id: grafana
    type: box
    label: Grafana
    position: { x: 530, y: 175 }
edges:
  - id: e1
    from: prom1
    to: sidecar1
  - id: e2
    from: prom2
    to: sidecar2
  - id: e3
    from: sidecar1
    to: query
    label: gRPC
  - id: e4
    from: sidecar2
    to: query
    label: gRPC
  - id: e5
    from: sidecar1
    to: objstore
    label: upload
  - id: e6
    from: sidecar2
    to: objstore
    label: upload
  - id: e7
    from: store
    to: objstore
    label: read
  - id: e8
    from: store
    to: query
    label: gRPC
  - id: e9
    from: query
    to: grafana
    label: PromQL
  - id: e10
    from: compact
    to: objstore
    label: compact
scenarios:
  - id: query-flow
    name: 쿼리 흐름
    steps:
      - action: highlight
        nodes: [grafana]
        style:
          color: "#3b82f6"
        duration: 500
      - action: animate-edge
        edge: e9
        label: "PromQL query"
        duration: 600
      - action: highlight
        nodes: [query]
        style:
          color: "#8b5cf6"
        duration: 600
      - action: animate-edge
        edge: e3
        label: "fan-out"
        duration: 400
      - action: animate-edge
        edge: e4
        label: "fan-out"
        duration: 400
      - action: highlight
        nodes: [sidecar1, sidecar2]
        style:
          color: "#10b981"
        duration: 500
      - action: animate-edge
        edge: e8
        label: "historical"
        duration: 500
      - action: highlight
        nodes: [store]
        style:
          color: "#f59e0b"
        duration: 500
  - id: upload-flow
    name: 블록 업로드 흐름
    steps:
      - action: highlight
        nodes: [prom1, prom2]
        style:
          color: "#3b82f6"
        duration: 600
      - action: animate-edge
        edge: e1
        label: "TSDB blocks"
        duration: 400
      - action: animate-edge
        edge: e2
        label: "TSDB blocks"
        duration: 400
      - action: highlight
        nodes: [sidecar1, sidecar2]
        style:
          color: "#10b981"
        duration: 500
      - action: animate-edge
        edge: e5
        label: "upload block"
        duration: 600
      - action: animate-edge
        edge: e6
        label: "upload block"
        duration: 600
      - action: highlight
        nodes: [objstore]
        style:
          color: "#f59e0b"
        duration: 800
      - action: animate-edge
        edge: e10
        label: "compaction"
        duration: 600
      - action: highlight
        nodes: [compact]
        style:
          color: "#ef4444"
        duration: 600`}
/>

### 핵심 컴포넌트

| 컴포넌트 | 역할 |
|---------|------|
| **Sidecar** | Prometheus와 함께 배포, 실시간 데이터 제공 및 블록 업로드 (블록 생성 후 2-3시간 지연) |
| **Query** | 여러 소스에서 데이터를 집계하여 글로벌 뷰 제공 |
| **Store Gateway** | Object Storage의 히스토리 데이터 쿼리 |
| **Compactor** | 블록 압축 및 다운샘플링으로 쿼리 성능 최적화 |
| **Ruler** | (선택) 글로벌 레벨의 recording/alerting rules |

## Kubernetes 배포 전략

### 1. Namespace 및 기본 설정

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: Secret
metadata:
  name: thanos-objstore-config
  namespace: monitoring
type: Opaque
stringData:
  objstore.yml: |
    type: S3
    config:
      bucket: thanos-metrics
      endpoint: s3.amazonaws.com
      region: ap-northeast-2
      access_key: ${AWS_ACCESS_KEY}
      secret_key: ${AWS_SECRET_KEY}
```

### 2. Headless Service 정의

DNS SRV 디스커버리를 위해 Headless Service가 필요합니다.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
spec:
  clusterIP: None
  selector:
    app: prometheus
  ports:
    - name: web
      port: 9090
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-sidecar
  namespace: monitoring
spec:
  clusterIP: None
  selector:
    thanos-store-api: "true"
  ports:
    - name: grpc
      port: 10901
---
apiVersion: v1
kind: Service
metadata:
  name: thanos-store
  namespace: monitoring
spec:
  clusterIP: None
  selector:
    app: thanos-store
  ports:
    - name: grpc
      port: 10901
```

### 3. Prometheus ConfigMap

Prometheus 설정에서 `external_labels`를 통해 replica 식별자를 추가합니다.

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      external_labels:
        cluster: production
        prometheus_replica: $(POD_NAME)

    scrape_configs:
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
```

### 4. Prometheus with Sidecar (StatefulSet)

HA 구성을 위해 최소 2개의 Prometheus replica를 배포합니다.

> **주의**: `retention.time=6h`는 Sidecar가 정상적으로 블록을 업로드한다는 가정 하에 설정됩니다. Sidecar 장애 시 데이터 손실 위험이 있으므로, 프로덕션 환경에서는 **12h 이상**을 권장합니다.

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: prometheus
  namespace: monitoring
spec:
  serviceName: prometheus
  # HA를 위한 replica 수. Prometheus는 분산 합의 시스템이 아니므로 quorum 불필요
  # 각 replica는 동일한 타겟을 독립적으로 스크랩 → 데이터 중복 발생 → Query에서 dedup 처리
  # 2개면 단일 장애점 제거에 충분. 3개 이상은 더 높은 내결함성이 필요한 경우만
  replicas: 2
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
        # Thanos Query가 이 label로 Store API 엔드포인트를 발견
        thanos-store-api: "true"
    spec:
      containers:
        # ============================================
        # Prometheus Container
        # ============================================
        - name: prometheus
          image: prom/prometheus:v2.47.0
          args:
            - --config.file=/etc/prometheus/prometheus.yml
            - --storage.tsdb.path=/prometheus

            # [TSDB Retention] 로컬 디스크 보존 기간
            # Sidecar 업로드 타이밍: 블록이 2h 완료 후 다음 블록 생성 시 업로드
            # 따라서 데이터 수집 → S3 업로드까지 약 2-4시간 지연 발생
            # 공식: retention >= 3 * max-block-duration (안전 마진)
            # 6h = 3 * 2h → Sidecar 장애 시 최소 3블록까지 로컬에서 복구 가능
            - --storage.tsdb.retention.time=6h

            # [Block Duration] TSDB 블록 생성 주기
            # min = max = 2h로 고정해야 Thanos Sidecar가 예측 가능하게 업로드
            # 2h는 Prometheus 기본값이자 Thanos 권장값
            # 더 작은 값(1h)은 업로드 빈도↑, 더 큰 값(4h)은 복구 지연↑
            - --storage.tsdb.min-block-duration=2h
            - --storage.tsdb.max-block-duration=2h

            # [Admin API] Sidecar의 reload 호출과 관리 작업에 필요
            - --web.enable-lifecycle  # /-/reload 엔드포인트 활성화
            - --web.enable-admin-api  # /api/v1/admin/* 엔드포인트 활성화
          ports:
            - containerPort: 9090
          # 리소스 가이드라인:
          # - 메모리: (active_series * 3KB) + (churn_rate * 10KB) + 1GB 오버헤드
          #   예: 100만 active series, churn 10%/day → ~3.5GB base memory
          # - CPU: 초당 샘플 수에 비례 (10만 samples/s ≈ 1 core)
          resources:
            requests:
              cpu: "500m"
              memory: "2Gi"
            limits:
              cpu: "2"
              memory: "8Gi"
          volumeMounts:
            - name: prometheus-data
              mountPath: /prometheus
            - name: prometheus-config
              mountPath: /etc/prometheus

        # ============================================
        # Thanos Sidecar Container
        # ============================================
        - name: thanos-sidecar
          image: quay.io/thanos/thanos:v0.32.0
          args:
            - sidecar

            # Prometheus TSDB 경로 - 블록 읽기 및 업로드에 사용
            - --tsdb.path=/prometheus

            # Prometheus API 주소 - 같은 Pod이므로 localhost 사용
            # Sidecar가 Prometheus 상태 확인 및 메타데이터 조회에 사용
            - --prometheus.url=http://localhost:9090

            # [gRPC] Store API 엔드포인트 - Query가 이 포트로 데이터 요청
            # 0.0.0.0 바인딩으로 클러스터 내 모든 IP에서 접근 허용
            - --grpc-address=0.0.0.0:10901

            # [HTTP] 메트릭 및 헬스체크 엔드포인트
            - --http-address=0.0.0.0:10902

            # Object Storage 설정 - S3/GCS/Azure Blob 등 지원
            - --objstore.config-file=/etc/thanos/objstore.yml
          ports:
            - containerPort: 10901
              name: grpc
            - containerPort: 10902
              name: http
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
          volumeMounts:
            # Prometheus TSDB 볼륨 공유 (읽기 전용)
            # Sidecar는 완료된 블록을 읽어서 S3로 업로드만 함, TSDB에 쓰지 않음
            - name: prometheus-data
              mountPath: /prometheus
              readOnly: true
            - name: thanos-objstore-config
              mountPath: /etc/thanos
      volumes:
        - name: prometheus-config
          configMap:
            name: prometheus-config
        - name: thanos-objstore-config
          secret:
            secretName: thanos-objstore-config
  volumeClaimTemplates:
    - metadata:
        name: prometheus-data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            # 스토리지 계산: samples/s * retention_seconds * bytes_per_sample * overhead
            # Prometheus TSDB 압축 후 약 1.2-1.5 bytes/sample
            # 예: 100K samples/s * 21600s (6h) * 1.5 bytes * 1.3 (WAL/체크포인트 오버헤드) ≈ 4.2GB
            # 50Gi는 대부분의 중소규모 클러스터에 충분한 여유 공간
            storage: 50Gi
```

### 5. Thanos Query (Deployment)

Query는 모든 데이터 소스를 집계하는 중앙 게이트웨이입니다. Stateless하므로 Deployment로 배포합니다.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-query
  namespace: monitoring
spec:
  # Query는 stateless → 수평 확장 가능
  # 부하에 따라 HPA로 자동 스케일링 권장
  replicas: 2
  selector:
    matchLabels:
      app: thanos-query
  template:
    metadata:
      labels:
        app: thanos-query
    spec:
      containers:
        - name: thanos-query
          image: quay.io/thanos/thanos:v0.32.0
          args:
            - query

            # [HTTP] Grafana/API 클라이언트용 PromQL 엔드포인트
            # Prometheus 호환 API 제공 (/api/v1/query, /api/v1/query_range)
            - --http-address=0.0.0.0:9090

            # [gRPC] 다른 Query 또는 Query Frontend와의 통신용
            - --grpc-address=0.0.0.0:10901

            # [Deduplication] 중복 제거에 사용할 레이블
            # 같은 메트릭을 수집하는 여러 Prometheus가 있을 때,
            # 이 레이블 값만 다르면 동일 데이터로 간주하고 하나만 반환
            # prometheus_replica=prometheus-0, prometheus-1 → 첫 번째 값만 유지
            - --query.replica-label=prometheus_replica

            # [Store Discovery] 데이터 소스 지정 방식
            # dnssrv+ 프리픽스: DNS SRV 레코드로 동적 디스커버리
            # _grpc._tcp: SRV 레코드의 서비스명과 프로토콜
            # Headless Service가 각 Pod의 IP를 SRV 레코드로 반환

            # Sidecar: 최근 2시간 이내 데이터 (아직 S3에 없는 블록)
            - --store=dnssrv+_grpc._tcp.thanos-sidecar.monitoring.svc

            # Store Gateway: S3의 히스토리 데이터 (2시간 이상 지난 블록)
            - --store=dnssrv+_grpc._tcp.thanos-store.monitoring.svc
          ports:
            - containerPort: 9090
              name: http
            - containerPort: 10901
              name: grpc
          # Query 리소스 가이드라인:
          # - 메모리: 동시 쿼리 수 * 쿼리당 메모리 (복잡한 쿼리 ~100MB)
          # - CPU: fan-out 및 결과 병합에 필요
          resources:
            requests:
              cpu: "250m"
              memory: "512Mi"
            limits:
              cpu: "1"
              memory: "2Gi"
```

### 6. Store Gateway (StatefulSet)

Store Gateway는 Object Storage의 블록을 쿼리합니다. 로컬 캐시를 사용하므로 StatefulSet으로 배포합니다.

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: thanos-store
  namespace: monitoring
spec:
  serviceName: thanos-store
  # Store Gateway 샤딩: 여러 replica가 있으면 블록을 분산 처리
  # --selector.relabel-config로 샤딩 규칙 설정 가능
  replicas: 2
  selector:
    matchLabels:
      app: thanos-store
  template:
    metadata:
      labels:
        app: thanos-store
        # Query가 이 label로 Store API 엔드포인트 발견
        thanos-store-api: "true"
    spec:
      containers:
        - name: thanos-store
          image: quay.io/thanos/thanos:v0.32.0
          args:
            - store

            # [Local Cache] 블록 인덱스 및 청크 캐시 디렉토리
            # 자주 조회되는 블록의 인덱스를 로컬에 캐시하여 S3 호출 감소
            # SSD 스토리지 권장 (IOPS가 쿼리 성능에 직접 영향)
            - --data-dir=/var/thanos/store

            # Object Storage 설정
            - --objstore.config-file=/etc/thanos/objstore.yml

            # [gRPC] Query로부터의 요청 수신
            - --grpc-address=0.0.0.0:10901

            # [HTTP] 메트릭 및 헬스체크
            - --http-address=0.0.0.0:10902

            # [성능 튜닝 옵션 - 프로덕션 권장]
            # --index-cache-size=1GB          # 인덱스 캐시 크기 (메모리)
            # --chunk-pool-size=4GB           # 청크 풀 크기 (메모리)
            # --store.grpc.series-max-concurrency=20  # 동시 series 요청 수
          ports:
            - containerPort: 10901
              name: grpc
            - containerPort: 10902
              name: http
          # Store Gateway 리소스 가이드라인:
          # - 메모리: index-cache-size + chunk-pool-size + 오버헤드
          # - CPU: S3 요청 처리 및 데이터 디코딩
          resources:
            requests:
              cpu: "250m"
              memory: "1Gi"
            limits:
              cpu: "1"
              memory: "4Gi"
          volumeMounts:
            - name: store-cache
              mountPath: /var/thanos/store
            - name: thanos-objstore-config
              mountPath: /etc/thanos
      volumes:
        - name: thanos-objstore-config
          secret:
            secretName: thanos-objstore-config
  volumeClaimTemplates:
    - metadata:
        name: store-cache
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            # 캐시 크기: 자주 조회되는 블록의 인덱스 + 임시 파일
            # 20Gi면 수백 개 블록의 인덱스 캐시 가능
            # 더 큰 환경에서는 50-100Gi 권장
            storage: 20Gi
```

### 7. Compactor (Singleton)

Compactor는 블록 압축, 다운샘플링, 보존 정책을 담당합니다. **반드시 단일 인스턴스**로 실행해야 합니다 (여러 개 실행 시 데이터 손상 위험).

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: thanos-compactor
  namespace: monitoring
spec:
  serviceName: thanos-compactor
  # ⚠️ CRITICAL: 절대로 1 이상으로 설정하지 마세요!
  # 여러 Compactor가 동시에 같은 블록을 처리하면 데이터 손상 발생
  # Compactor는 lock 파일로 보호하지만, 완벽하지 않음
  replicas: 1
  selector:
    matchLabels:
      app: thanos-compactor
  template:
    metadata:
      labels:
        app: thanos-compactor
    spec:
      containers:
        - name: thanos-compactor
          image: quay.io/thanos/thanos:v0.32.0
          args:
            - compact

            # [Working Directory] 압축 작업용 임시 디렉토리
            # 블록을 S3에서 다운로드 → 병합 → 다시 업로드하는 과정에서 사용
            # 충분한 공간 필요 (최소 가장 큰 블록의 3배)
            - --data-dir=/var/thanos/compact

            # Object Storage 설정
            - --objstore.config-file=/etc/thanos/objstore.yml

            # [HTTP] 메트릭 엔드포인트 (thanos_compact_* 메트릭 노출)
            - --http-address=0.0.0.0:10902

            # [Daemon Mode] 첫 압축 완료 후 계속 실행하며 주기적으로 압축
            # 이 옵션 없으면 한 번 압축 후 종료 (CronJob 방식)
            - --wait

            # ============================================
            # [Retention Policy] 해상도별 보존 기간
            # ============================================
            # ⚠️ 중요: 다운샘플링은 블록이 최소 40시간 이상 지난 후에만 수행됨
            # 따라서 raw retention은 최소 40h 이상이어야 다운샘플링 가능

            # Raw 데이터: 원본 해상도 (보통 15s~1m 간격)
            # 상세 분석 및 디버깅에 필요, 스토리지 비용 가장 높음
            # 30일 = 약 2.6M 데이터포인트/시계열 (15s 간격 기준)
            - --retention.resolution-raw=30d

            # 5분 다운샘플: Raw 데이터의 min/max/sum/count 집계
            # 일반 대시보드 및 알림에 충분한 해상도
            # 60일 = 약 17K 데이터포인트/시계열
            - --retention.resolution-5m=60d

            # 1시간 다운샘플: 장기 트렌드 분석용
            # 연간 용량 계획, 비용 분석 등에 사용
            # 1년 = 약 8.7K 데이터포인트/시계열
            - --retention.resolution-1h=1y

            # ============================================
            # [Downsampling] 다운샘플링 동시성
            # ============================================
            # CPU 코어 수에 맞게 조정 (너무 높으면 메모리 부족)
            # 4 = 동시에 4개 블록을 다운샘플링
            - --downsample.concurrency=4

            # [추가 권장 옵션]
            # --compact.concurrency=1            # 압축 동시성 (기본 1)
            # --delete-delay=48h                 # 삭제 전 대기 시간 (복구용)
            # --compact.cleanup-interval=5m     # 임시 파일 정리 주기
          # Compactor 리소스 가이드라인:
          # - 메모리: 블록 크기에 비례 (큰 블록 압축 시 최대 4-8GB)
          # - CPU: 다운샘플링 및 압축은 CPU 집약적
          # - 디스크 I/O: 블록 읽기/쓰기가 빈번하므로 SSD 권장
          resources:
            requests:
              cpu: "500m"
              memory: "2Gi"
            limits:
              cpu: "2"
              memory: "8Gi"
          volumeMounts:
            - name: compact-data
              mountPath: /var/thanos/compact
            - name: thanos-objstore-config
              mountPath: /etc/thanos
      volumes:
        - name: thanos-objstore-config
          secret:
            secretName: thanos-objstore-config
  volumeClaimTemplates:
    - metadata:
        name: compact-data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            # 작업 공간 계산: 가장 큰 블록 * 3 (다운로드+작업+업로드)
            # 예: 2시간 블록이 10GB라면 최소 30GB 필요
            # 100Gi는 대부분의 환경에서 충분한 여유 공간 제공
            storage: 100Gi
```

## 데이터 흐름 상세

### 쿼리 처리 흐름

<AnimFlowEmbed
  id="query-detail"
  title="Thanos Query Processing"
  height={400}
  yaml={`version: "1.0"
nodes:
  - id: client
    type: box
    label: Grafana/API
    position: { x: 80, y: 180 }
  - id: query
    type: box
    label: Thanos Query
    position: { x: 250, y: 180 }
  - id: sidecar
    type: box
    label: Sidecar (실시간)
    position: { x: 450, y: 100 }
  - id: store
    type: database
    label: Store GW (히스토리)
    position: { x: 450, y: 260 }
edges:
  - id: e1
    from: client
    to: query
    label: PromQL
  - id: e2
    from: query
    to: sidecar
    label: gRPC StoreAPI
  - id: e3
    from: query
    to: store
    label: gRPC StoreAPI
  - id: e4
    from: sidecar
    to: query
    label: Series
  - id: e5
    from: store
    to: query
    label: Series
scenarios:
  - id: fanout-query
    name: Fan-out 쿼리 처리
    steps:
      - action: highlight
        nodes: [client]
        style:
          color: "#6b7280"
        duration: 400
      - action: animate-edge
        edge: e1
        label: "rate(http_requests[5m])"
        duration: 600
      - action: highlight
        nodes: [query]
        style:
          color: "#3b82f6"
        duration: 500
      - action: animate-edge
        edge: e2
        label: "recent data"
        duration: 400
      - action: animate-edge
        edge: e3
        label: "historical data"
        duration: 400
      - action: highlight
        nodes: [sidecar, store]
        style:
          color: "#10b981"
        duration: 600
      - action: animate-edge
        edge: e4
        label: "series chunks"
        duration: 500
      - action: animate-edge
        edge: e5
        label: "series chunks"
        duration: 500
      - action: highlight
        nodes: [query]
        style:
          color: "#8b5cf6"
        duration: 600`}
/>

Thanos Query는 **Fan-out** 방식으로 동작합니다:

1. 클라이언트가 PromQL 쿼리 요청
2. Query가 모든 Store API 엔드포인트에 병렬 요청
3. Sidecar: 최근 데이터 (아직 업로드되지 않은 블록)
4. Store Gateway: Object Storage의 히스토리 데이터
5. Query가 결과를 병합하고 중복 제거

### Deduplication 원리

같은 메트릭을 수집하는 여러 Prometheus 인스턴스가 있을 때, Query는 `--query.replica-label` 설정을 통해 중복을 제거합니다.

```yaml
# Prometheus 설정에 replica label 추가
global:
  external_labels:
    cluster: production
    prometheus_replica: $(POD_NAME)  # prometheus-0, prometheus-1
```

## 다운샘플링 전략

<AnimFlowEmbed
  id="downsampling"
  title="Compactor Downsampling Process"
  height={380}
  yaml={`version: "1.0"
nodes:
  - id: raw
    type: database
    label: Raw (5s resolution)
    position: { x: 100, y: 180 }
  - id: compact
    type: box
    label: Compactor
    position: { x: 300, y: 180 }
  - id: ds5m
    type: database
    label: 5m Downsampled
    position: { x: 500, y: 100 }
  - id: ds1h
    type: database
    label: 1h Downsampled
    position: { x: 500, y: 260 }
edges:
  - id: e1
    from: raw
    to: compact
    label: read
  - id: e2
    from: compact
    to: ds5m
    label: aggregate
  - id: e3
    from: compact
    to: ds1h
    label: aggregate
scenarios:
  - id: downsample-flow
    name: 다운샘플링 과정
    steps:
      - action: highlight
        nodes: [raw]
        style:
          color: "#3b82f6"
        duration: 600
      - action: animate-edge
        edge: e1
        label: "30+ days old"
        duration: 600
      - action: highlight
        nodes: [compact]
        style:
          color: "#f59e0b"
        duration: 800
      - action: animate-edge
        edge: e2
        label: "min/max/sum/count"
        duration: 600
      - action: highlight
        nodes: [ds5m]
        style:
          color: "#10b981"
        duration: 500
      - action: animate-edge
        edge: e3
        label: "min/max/sum/count"
        duration: 600
      - action: highlight
        nodes: [ds1h]
        style:
          color: "#8b5cf6"
        duration: 500`}
/>

Compactor의 다운샘플링 전략:

| Resolution | 보존 기간 | 용도 |
|------------|----------|------|
| Raw | 30일 | 상세 분석, 디버깅 |
| 5분 | 60일 | 일반적인 대시보드 |
| 1시간 | 1년 | 장기 트렌드 분석 |

## 운영 고려사항

### 1. Object Storage 비용 최적화

```yaml
# Compactor retention 설정
args:
  - --retention.resolution-raw=14d      # 비용 절감을 위해 줄임
  - --retention.resolution-5m=90d
  - --retention.resolution-1h=365d
```

### 2. Query 성능 튜닝

```yaml
args:
  - --query.timeout=2m
  - --query.max-concurrent=20
  - --query.lookback-delta=5m
  - --query.partial-response    # 일부 Store 실패 시에도 응답
```

> **`--query.partial-response` 트레이드오프**: 이 옵션은 일부 Store가 응답하지 않아도 부분 결과를 반환합니다. **가용성 vs 일관성** 트레이드오프입니다. 데이터 정확성이 중요한 경우 비활성화하고, 가용성이 우선인 경우 활성화하세요.

### 3. Store Gateway 캐싱

```yaml
args:
  - --index-cache-size=1GB
  - --chunk-pool-size=4GB
```

### 4. Alerting on Thanos

```yaml
# Thanos 자체 모니터링 알림
groups:
  - name: thanos
    rules:
      - alert: ThanosSidecarUnhealthy
        expr: thanos_sidecar_prometheus_up != 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Thanos Sidecar cannot reach Prometheus"

      - alert: ThanosCompactorHalted
        expr: thanos_compact_halted == 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Thanos Compactor has halted"

      - alert: ThanosCompactMultipleRunning
        expr: sum(up{job=~".*thanos-compact.*"}) > 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Multiple Thanos Compactors running - data corruption risk"

      - alert: ThanosQueryGrpcErrorRate
        expr: |
          rate(grpc_server_handled_total{job=~".*thanos-query.*", grpc_code!="OK"}[5m])
          / rate(grpc_server_handled_total{job=~".*thanos-query.*"}[5m])
          > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Thanos Query gRPC error rate > 5%"

      - alert: ThanosStoreGrpcErrorRate
        expr: |
          rate(grpc_server_handled_total{job=~".*thanos-store.*", grpc_code!="OK"}[5m])
          / rate(grpc_server_handled_total{job=~".*thanos-store.*"}[5m])
          > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Thanos Store Gateway gRPC error rate > 5%"
```

## 멀티 클러스터 구성

<AnimFlowEmbed
  id="multi-cluster"
  title="Multi-Cluster Federation"
  height={450}
  yaml={`version: "1.0"
nodes:
  - id: cluster1
    type: box
    label: Cluster A (Seoul)
    position: { x: 80, y: 100 }
  - id: cluster2
    type: box
    label: Cluster B (Tokyo)
    position: { x: 80, y: 250 }
  - id: s3a
    type: database
    label: S3 (Seoul)
    position: { x: 280, y: 100 }
  - id: s3b
    type: database
    label: S3 (Tokyo)
    position: { x: 280, y: 250 }
  - id: globalquery
    type: box
    label: Global Thanos Query
    position: { x: 480, y: 175 }
  - id: grafana
    type: box
    label: Global Grafana
    position: { x: 650, y: 175 }
edges:
  - id: e1
    from: cluster1
    to: s3a
    label: upload
  - id: e2
    from: cluster2
    to: s3b
    label: upload
  - id: e3
    from: s3a
    to: globalquery
    label: Store API
  - id: e4
    from: s3b
    to: globalquery
    label: Store API
  - id: e5
    from: globalquery
    to: grafana
    label: PromQL
scenarios:
  - id: global-query
    name: 글로벌 쿼리
    steps:
      - action: highlight
        nodes: [grafana]
        style:
          color: "#3b82f6"
        duration: 500
      - action: animate-edge
        edge: e5
        label: "sum by (cluster)"
        duration: 600
      - action: highlight
        nodes: [globalquery]
        style:
          color: "#8b5cf6"
        duration: 600
      - action: animate-edge
        edge: e3
        label: "Seoul data"
        duration: 500
      - action: animate-edge
        edge: e4
        label: "Tokyo data"
        duration: 500
      - action: highlight
        nodes: [s3a, s3b]
        style:
          color: "#f59e0b"
        duration: 600
      - action: highlight
        nodes: [cluster1, cluster2]
        style:
          color: "#10b981"
        duration: 500`}
/>

각 클러스터의 Prometheus + Sidecar가 독립적으로 동작하고, Global Query가 모든 데이터 소스를 집계합니다.

## 결론

Thanos를 활용한 Prometheus HA 구성은:

- **고가용성**: 다중 Prometheus replica + 중복 제거
- **장기 보존**: Object Storage 기반 무제한 저장
- **글로벌 뷰**: 멀티 클러스터 통합 쿼리
- **비용 효율**: 다운샘플링으로 스토리지 최적화

복잡해 보이지만, 각 컴포넌트의 역할을 이해하면 운영이 수월해집니다. 프로덕션 환경에서는 반드시 Thanos 자체에 대한 모니터링과 알림도 구성하세요.

## 참고 자료

- [Thanos 공식 문서](https://thanos.io/tip/thanos/getting-started.md/)
- [Prometheus Operator with Thanos](https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/thanos.md)
- [Thanos Design](https://thanos.io/tip/thanos/design.md/)
